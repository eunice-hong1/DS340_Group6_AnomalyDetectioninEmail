{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkQzXPCXUxme"
   },
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 843 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[K     |████████████████████████████████| 502 kB 702 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/nataliechow/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (1.25.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[K     |████████████████████████████████| 341 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/nataliechow/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_spam_ham_phishing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove phishing emails, only consider ham and spam:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75419, 95)\n"
     ]
    }
   ],
   "source": [
    "df = df[df['label'] != 2]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    50199\n",
       "0    25220\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25220, 95)\n",
      "(50199, 95)\n"
     ]
    }
   ],
   "source": [
    "df_ham = df[df['label'] == 0]\n",
    "df_spam = df[df['label'] == 1]\n",
    "print(df_ham.shape)\n",
    "print(df_spam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham_Y = df_ham['label']\n",
    "df_ham_X = df_ham.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take 50% of the ham emails to be used for training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test_ham, y_train, y_test_ham = train_test_split(df_ham_X, df_ham_Y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12610, 94)\n",
      "(12610, 94)\n",
      "(12610,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test_ham.shape)\n",
    "print(y_test_ham.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the test set of spam emails, which contains the same number of emails as ham test (12,610):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam_Y = df_spam['label']\n",
    "df_spam_X = df_spam.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50199,)\n",
      "(50199, 94)\n"
     ]
    }
   ],
   "source": [
    "print(df_spam_Y.shape)\n",
    "print(df_spam_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_test_spam, _, y_test_spam = train_test_split(df_spam_X, df_spam_Y, test_size=12610, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12610, 94)\n",
      "(12610,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_spam.shape)\n",
    "print(y_test_spam.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine the test set of spam and ham emails into one:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_X = X_test_ham.append(X_test_spam, ignore_index=True)\n",
    "#test_Y = y_test_ham.append(y_test_spam, ignore_index=True)\n",
    "test_X = X_test_ham._append(X_test_spam, ignore_index=True)\n",
    "test_Y = y_test_ham._append(y_test_spam, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25220, 94)\n",
      "(25220,)\n"
     ]
    }
   ],
   "source": [
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = test_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OC-SVM predicts either 1 or -1, so need to adjust labels:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = pd.DataFrame(test_Y, columns=['label'])\n",
    "test_Y.loc[test_Y['label'] == 1, 'label'] = -1\n",
    "test_Y.loc[test_Y['label'] == 0, 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1       12610\n",
       " 1       12610\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfqcyuLalhxp"
   },
   "source": [
    "**Apply a standard scaler to the full data set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "j6TAQHBjlhJ6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(test_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "test_X = pd.DataFrame(test_X, columns=features_list)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = test_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m OneClassSVM(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m'\u001b[39m, degree\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mfit(X_train)\n\u001b[0;32m----> 4\u001b[0m results \u001b[39m=\u001b[39m permutation_importance(model, X_train, y_train, \n\u001b[1;32m      5\u001b[0m                                  scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, n_repeats\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m importance \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mimportances_mean\n\u001b[1;32m      8\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m(\u001b[39m25\u001b[39m, \u001b[39m7\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:289\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    285\u001b[0m     scorer \u001b[39m=\u001b[39m _MultimetricScorer(scorers\u001b[39m=\u001b[39mscorers_dict)\n\u001b[1;32m    287\u001b[0m baseline_score \u001b[39m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m--> 289\u001b[0m scores \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[1;32m    290\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[1;32m    291\u001b[0m         estimator,\n\u001b[1;32m    292\u001b[0m         X,\n\u001b[1;32m    293\u001b[0m         y,\n\u001b[1;32m    294\u001b[0m         sample_weight,\n\u001b[1;32m    295\u001b[0m         col_idx,\n\u001b[1;32m    296\u001b[0m         random_seed,\n\u001b[1;32m    297\u001b[0m         n_repeats,\n\u001b[1;32m    298\u001b[0m         scorer,\n\u001b[1;32m    299\u001b[0m         max_samples,\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    301\u001b[0m     \u001b[39mfor\u001b[39;49;00m col_idx \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(X\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    302\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(baseline_score, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    305\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    306\u001b[0m         name: _create_importances_bunch(\n\u001b[1;32m    307\u001b[0m             baseline_score[name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m baseline_score\n\u001b[1;32m    312\u001b[0m     }\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = OneClassSVM(kernel='poly', degree=6)\n",
    "model.fit(X_train)\n",
    "\n",
    "results = permutation_importance(model, X_train, y_train, \n",
    "                                 scoring='accuracy', n_repeats=2, n_jobs=-1)\n",
    "importance = results.importances_mean\n",
    "\n",
    "fig = plt.figure(figsize =(25, 7))\n",
    "\n",
    "importances_sorted = sorted(zip(importance, feature_list), reverse=True)\n",
    "feature_sorted, importance_sorted = zip(*importances_sorted)\n",
    "\n",
    "perm_svm_feature_importances = importance_sorted\n",
    "\n",
    "print(\"Top features sorted:\")\n",
    "for x, imp in zip(feature_sorted, importance_sorted):\n",
    "  print('Feature: %s, Score: %f' % (imp, x))\n",
    "\n",
    "for x, imp in zip(feature_sorted, importance_sorted):\n",
    "  print('\\'' + imp + '\\',')\n",
    "\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar([x for x in importance_sorted], feature_sorted, width=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce the features:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_list = [\n",
    "'lines',\n",
    "'content-length',\n",
    "'domain_match_errors-to_sender',\n",
    "'missing_list-subscribe',\n",
    "'str_precedence_list',\n",
    "'missing_list-post',\n",
    "'missing_list-id',\n",
    "'missing_list-help',\n",
    "'missing_received-spf',\n",
    "'domain_match_to_received',\n",
    "'missing_x-spam-check-by',\n",
    "'missing_precedence',\n",
    "'missing_mailing-list',\n",
    "'str_return-path_bounce',\n",
    "'missing_list-unsubscribe',\n",
    "'day_of_week',\n",
    "'missing_x-mailing-list',\n",
    "'hops',\n",
    "'missing_status',\n",
    "'missing_content-length',\n",
    "'domain_match_from_return-path',\n",
    "'missing_references',\n",
    "'missing_lines',\n",
    "'number_replies',\n",
    "'missing_cc',\n",
    "'missing_in-reply-to',\n",
    "'time_zone',\n",
    "'span_time',\n",
    "'missing_x-spam-status',\n",
    "'missing_content-disposition',\n",
    "'missing_x-mimeole',\n",
    "'missing_thread-index',\n",
    "'missing_x-mailer',\n",
    "'domain_match_to_message-id',\n",
    "'conseq_received_bad',\n",
    "'missing_user-agent',\n",
    "'domain_match_from_reply-to',\n",
    "'domain_match_errors-to_from',\n",
    "'domain_match_return-path_reply-to',\n",
    "'domain_match_message-id_reply-to',\n",
    "'missing_errors-to',\n",
    "'missing_sender',\n",
    "'domain_match_errors-to_message-id',\n",
    "'domain_match_to_from',\n",
    "'domain_match_errors-to_reply-to',\n",
    "'domain_match_message-id_sender',\n",
    "'missing_mime-version',\n",
    "'missing_list-archive',\n",
    "'conseq_received_good',\n",
    "'str_message-ID_dollar',\n",
    "'domain_val_message-id',\n",
    "'num_recipients_to',\n",
    "'missing_x-beenthere',\n",
    "'num_recipients_cc',\n",
    "'domain_match_sender_from',\n",
    "'missing_x-msmail-priority',\n",
    "'str_content-type_texthtml',\n",
    "'str_content-encoding_empty',\n",
    "'missing_content-transfer-encoding',\n",
    "'missing_content-type',\n",
    "'email_match_from_reply-to'\n",
    "]\n",
    "\n",
    "test_X = test_X[new_feature_list]\n",
    "X_train = X_train[new_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25220, 61)\n",
      "(12610, 61)\n"
     ]
    }
   ],
   "source": [
    "print(test_X.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGZ561te2ONO"
   },
   "source": [
    "# **Testing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XR4Wc3Fqh_W"
   },
   "source": [
    "**OC-SVM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "oZ239URUq-tx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.33386201427439\n",
      "F1 Score: 88.24300699300699\n",
      "Recall: 80.05551149881047\n",
      "Precision: 98.29600778967867\n",
      "ROC AUC: 89.33386201427439\n",
      "Confusion Matrix: [[12435   175]\n",
      " [ 2515 10095]]\n",
      "Wall time: 9.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ocsvm = OneClassSVM(kernel='poly', degree=6, nu=0.2)\n",
    "ocsvm.fit(X_train)\n",
    "\n",
    "# Test the model on the test set\n",
    "predictions = ocsvm.predict(test_X)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('Accuracy:', accuracy_score(test_Y, predictions)*100)\n",
    "print('F1 Score:', f1_score(test_Y, predictions)*100)\n",
    "print('Recall:', recall_score(test_Y, predictions)*100)\n",
    "print('Precision:', precision_score(test_Y, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(test_Y, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(test_Y, predictions))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sCMEqns8jY-1",
    "F5A997Ekjh0E",
    "KvWjb8GwOM-y",
    "rJJ4WHSBFTWc",
    "nqHSyA4SyJ7K",
    "xhkNe2ql-cFP",
    "fMwsPWxpi2cG",
    "-_nEjwFOjUDI",
    "MyekmTK3q5TC",
    "RkQzXPCXUxme",
    "P1zXPP6trxSN",
    "iGZ561te2ONO",
    "rffvHbuzGO8c"
   ],
   "name": "Capstone Project - Email Headers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
