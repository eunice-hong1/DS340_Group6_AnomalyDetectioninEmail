{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkQzXPCXUxme"
   },
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_spam_ham_phishing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    50199\n",
       "0    25220\n",
       "2     1288\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET ONLY PHISHING/HAM EMAILS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288, 95)\n"
     ]
    }
   ],
   "source": [
    "# Remove spam emails, only consider phishing: (ham = 0, spam = 1, phishing = 2)\n",
    "df_phish = df[(df['label'] == 2)]\n",
    "print(df_phish.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25220, 95)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ham data\n",
    "df_ham = df[(df['label'] == 0)]\n",
    "df_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13898, 95)\n"
     ]
    }
   ],
   "source": [
    "# Split ham data into 50/50 so some can be used for validation\n",
    "df_split = df_ham[:int(len(df_ham)/2)]\n",
    "df_split = df_split.reset_index()\n",
    "df_split = df_split.drop('index', axis=1)\n",
    "\n",
    "df_val_ham = df_ham[int(len(df_ham)/2):]\n",
    "df_val_ham = df_val_ham.reset_index()\n",
    "df_val_ham = df_val_ham.drop('index', axis=1)\n",
    "\n",
    "df = pd.concat([df_phish, df_split])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12610\n",
       "2     1288\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hops</th>\n",
       "      <th>missing_subject</th>\n",
       "      <th>missing_to</th>\n",
       "      <th>missing_content-type</th>\n",
       "      <th>missing_mime-version</th>\n",
       "      <th>missing_x-mailer</th>\n",
       "      <th>missing_content-transfer-encoding</th>\n",
       "      <th>missing_x-mimeole</th>\n",
       "      <th>missing_x-priority</th>\n",
       "      <th>missing_list-id</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_match_errors-to_reply-to</th>\n",
       "      <th>domain_match_sender_from</th>\n",
       "      <th>domain_match_references_reply-to</th>\n",
       "      <th>domain_match_references_in-reply-to</th>\n",
       "      <th>domain_match_references_to</th>\n",
       "      <th>domain_match_from_reply-to</th>\n",
       "      <th>domain_match_to_from</th>\n",
       "      <th>domain_match_to_message-id</th>\n",
       "      <th>domain_match_to_received</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2576 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hops  missing_subject  missing_to  missing_content-type  \\\n",
       "0        0                0           0                     0   \n",
       "1        1                0           0                     0   \n",
       "2        2                0           0                     0   \n",
       "3        0                0           0                     0   \n",
       "4        1                0           0                     0   \n",
       "...    ...              ...         ...                   ...   \n",
       "2571     0                0           0                     0   \n",
       "2572     1                0           0                     0   \n",
       "2573     1                0           0                     0   \n",
       "2574     0                0           0                     0   \n",
       "2575     0                0           0                     0   \n",
       "\n",
       "      missing_mime-version  missing_x-mailer  \\\n",
       "0                        0                 1   \n",
       "1                        0                 1   \n",
       "2                        0                 1   \n",
       "3                        0                 1   \n",
       "4                        1                 1   \n",
       "...                    ...               ...   \n",
       "2571                     0                 1   \n",
       "2572                     0                 1   \n",
       "2573                     0                 1   \n",
       "2574                     0                 1   \n",
       "2575                     0                 0   \n",
       "\n",
       "      missing_content-transfer-encoding  missing_x-mimeole  \\\n",
       "0                                     1                  0   \n",
       "1                                     1                  1   \n",
       "2                                     0                  1   \n",
       "3                                     1                  1   \n",
       "4                                     0                  1   \n",
       "...                                 ...                ...   \n",
       "2571                                  0                  1   \n",
       "2572                                  0                  1   \n",
       "2573                                  0                  1   \n",
       "2574                                  1                  1   \n",
       "2575                                  1                  0   \n",
       "\n",
       "      missing_x-priority  missing_list-id  ...  \\\n",
       "0                      1                1  ...   \n",
       "1                      1                1  ...   \n",
       "2                      1                0  ...   \n",
       "3                      1                1  ...   \n",
       "4                      1                0  ...   \n",
       "...                  ...              ...  ...   \n",
       "2571                   1                1  ...   \n",
       "2572                   1                0  ...   \n",
       "2573                   1                0  ...   \n",
       "2574                   1                1  ...   \n",
       "2575                   1                1  ...   \n",
       "\n",
       "      domain_match_errors-to_reply-to  domain_match_sender_from  \\\n",
       "0                                   0                         0   \n",
       "1                                   0                         0   \n",
       "2                                   0                         0   \n",
       "3                                   0                         0   \n",
       "4                                   1                         1   \n",
       "...                               ...                       ...   \n",
       "2571                                0                         0   \n",
       "2572                                0                         0   \n",
       "2573                                0                         1   \n",
       "2574                                0                         0   \n",
       "2575                                0                         0   \n",
       "\n",
       "      domain_match_references_reply-to  domain_match_references_in-reply-to  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    1   \n",
       "4                                    0                                    0   \n",
       "...                                ...                                  ...   \n",
       "2571                                 0                                    0   \n",
       "2572                                 0                                    0   \n",
       "2573                                 0                                    0   \n",
       "2574                                 0                                    0   \n",
       "2575                                 0                                    0   \n",
       "\n",
       "      domain_match_references_to  domain_match_from_reply-to  \\\n",
       "0                              0                           0   \n",
       "1                              0                           1   \n",
       "2                              0                           0   \n",
       "3                              0                           0   \n",
       "4                              0                           1   \n",
       "...                          ...                         ...   \n",
       "2571                           0                           0   \n",
       "2572                           0                           0   \n",
       "2573                           0                           0   \n",
       "2574                           0                           0   \n",
       "2575                           0                           1   \n",
       "\n",
       "      domain_match_to_from  domain_match_to_message-id  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        1                           0   \n",
       "4                        1                           1   \n",
       "...                    ...                         ...   \n",
       "2571                     0                           0   \n",
       "2572                     0                           0   \n",
       "2573                     1                           1   \n",
       "2574                     0                           0   \n",
       "2575                     0                           0   \n",
       "\n",
       "      domain_match_to_received  label  \n",
       "0                            1      0  \n",
       "1                            0      1  \n",
       "2                            0      0  \n",
       "3                            0      1  \n",
       "4                            0      0  \n",
       "...                        ...    ...  \n",
       "2571                         0      1  \n",
       "2572                         0      0  \n",
       "2573                         0      0  \n",
       "2574                         0      1  \n",
       "2575                         1      0  \n",
       "\n",
       "[2576 rows x 95 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly Sample 1288 Ham emails to create a balanced dataset (match the number of phishing emails)\n",
    "df_ham = df[df['label'] == 0].sample(1288)\n",
    "df_phish = df[df['label'] == 2]\n",
    "\n",
    "df_phish = df_phish.assign(label=1)\n",
    "\n",
    "df_new = df_ham._append(df_phish, ignore_index=True)\n",
    "df_new = df_new.sample(frac=1)\n",
    "df = df_new.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1288\n",
       "1    1288\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FEATURE SELECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce feature set\n",
    "# The only features that are kept are domain matching features, as these should generalize across very different email datasets without issue.\n",
    "\n",
    "feature_list = [\n",
    "'domain_match_from_return-path',\n",
    "'domain_match_message-id_from',\n",
    "'domain_match_message-id_return-path',\n",
    "'domain_match_to_from',\n",
    "'domain_match_errors-to_from',\n",
    "'domain_match_message-id_reply-to',\n",
    "'domain_match_errors-to_message-id',\n",
    "'domain_match_sender_from',\n",
    "'domain_match_to_received',\n",
    "'domain_match_errors-to_reply-to',\n",
    "'domain_match_to_message-id',\n",
    "'label']\n",
    "\n",
    "feature_list = ['domain_val_message-id',\n",
    "       'domain_match_message-id_from', 'domain_match_from_return-path',\n",
    "       'domain_match_message-id_return-path', 'domain_match_message-id_sender',\n",
    "       'domain_match_message-id_reply-to', 'domain_match_return-path_reply-to',\n",
    "       'domain_match_reply-to_to', 'domain_match_to_in-reply-to',\n",
    "       'domain_match_errors-to_message-id', 'domain_match_errors-to_from',\n",
    "       'domain_match_errors-to_sender', 'domain_match_errors-to_reply-to',\n",
    "       'domain_match_sender_from', 'domain_match_references_reply-to',\n",
    "       'domain_match_references_in-reply-to', 'domain_match_references_to',\n",
    "       'domain_match_from_reply-to', 'domain_match_to_from',\n",
    "       'domain_match_to_message-id', 'domain_match_to_received', 'label']\n",
    "\n",
    "df = df[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y = df['label']\n",
    "df_X = df.drop('label', axis=1)\n",
    "\n",
    "features_list = df_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "id": "j6TAQHBjlhJ6"
   },
   "outputs": [],
   "source": [
    "# Apply a standard scaler to the full data set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(df_X)\n",
    "df_X = scaler.transform(df_X)\n",
    "df_X = pd.DataFrame(df_X, columns=features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking the data into a test and training set (20% test, 80% train)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 22)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_val_message-id</th>\n",
       "      <th>domain_match_message-id_from</th>\n",
       "      <th>domain_match_from_return-path</th>\n",
       "      <th>domain_match_message-id_return-path</th>\n",
       "      <th>domain_match_message-id_sender</th>\n",
       "      <th>domain_match_message-id_reply-to</th>\n",
       "      <th>domain_match_return-path_reply-to</th>\n",
       "      <th>domain_match_reply-to_to</th>\n",
       "      <th>domain_match_to_in-reply-to</th>\n",
       "      <th>domain_match_errors-to_message-id</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_match_errors-to_reply-to</th>\n",
       "      <th>domain_match_sender_from</th>\n",
       "      <th>domain_match_references_reply-to</th>\n",
       "      <th>domain_match_references_in-reply-to</th>\n",
       "      <th>domain_match_references_to</th>\n",
       "      <th>domain_match_from_reply-to</th>\n",
       "      <th>domain_match_to_from</th>\n",
       "      <th>domain_match_to_message-id</th>\n",
       "      <th>domain_match_to_received</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain_val_message-id  domain_match_message-id_from  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             1   \n",
       "3                      0                             0   \n",
       "4                      0                             1   \n",
       "\n",
       "   domain_match_from_return-path  domain_match_message-id_return-path  \\\n",
       "0                              1                                    0   \n",
       "1                              0                                    0   \n",
       "2                              0                                    0   \n",
       "3                              1                                    0   \n",
       "4                              1                                    1   \n",
       "\n",
       "   domain_match_message-id_sender  domain_match_message-id_reply-to  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 0   \n",
       "2                               0                                 0   \n",
       "3                               0                                 0   \n",
       "4                               1                                 1   \n",
       "\n",
       "   domain_match_return-path_reply-to  domain_match_reply-to_to  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  1                         1   \n",
       "\n",
       "   domain_match_to_in-reply-to  domain_match_errors-to_message-id  ...  \\\n",
       "0                            0                                  0  ...   \n",
       "1                            0                                  0  ...   \n",
       "2                            0                                  0  ...   \n",
       "3                            0                                  0  ...   \n",
       "4                            0                                  1  ...   \n",
       "\n",
       "   domain_match_errors-to_reply-to  domain_match_sender_from  \\\n",
       "0                                0                         0   \n",
       "1                                0                         0   \n",
       "2                                0                         0   \n",
       "3                                0                         0   \n",
       "4                                1                         1   \n",
       "\n",
       "   domain_match_references_reply-to  domain_match_references_in-reply-to  \\\n",
       "0                                 0                                    0   \n",
       "1                                 0                                    0   \n",
       "2                                 0                                    0   \n",
       "3                                 0                                    1   \n",
       "4                                 0                                    0   \n",
       "\n",
       "   domain_match_references_to  domain_match_from_reply-to  \\\n",
       "0                           0                           0   \n",
       "1                           0                           1   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           1   \n",
       "\n",
       "   domain_match_to_from  domain_match_to_message-id  domain_match_to_received  \\\n",
       "0                     0                           0                         1   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           0                         0   \n",
       "4                     1                           1                         0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      1  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOVELTY: GET VALIDATION DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed in order to have ham data\n",
    "df_val = pd.read_csv('preprocessed_phishing_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The solution to get ham data is to transfer from other data...\n",
    "\n",
    "df_val = pd.concat([df_val, df_val_ham])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12610\n",
       "2      245\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Sample 245 Ham emails to create a balanced dataset\n",
    "df_ham_val = df_val[df_val['label'] == 0].sample(245)\n",
    "\n",
    "df_phish_val = df_val[df_val['label'] == 2]\n",
    "\n",
    "df_phish_val = df_phish_val.assign(label=1)\n",
    "\n",
    "df_new_val = df_ham_val._append(df_phish_val, ignore_index=True)\n",
    "\n",
    "df_new_val = df_new_val.sample(frac=1)\n",
    "df_val = df_new_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce feature set\n",
    "# The only features that are kept are domain matching features, as these should generalize across very different email datasets without issue.\n",
    "\n",
    "feature_list = [\n",
    "'domain_match_from_return-path',\n",
    "'domain_match_message-id_from',\n",
    "'domain_match_message-id_return-path',\n",
    "'domain_match_to_from',\n",
    "'domain_match_errors-to_from',\n",
    "'domain_match_message-id_reply-to',\n",
    "'domain_match_errors-to_message-id',\n",
    "'domain_match_sender_from',\n",
    "'domain_match_to_received',\n",
    "'domain_match_errors-to_reply-to',\n",
    "'domain_match_to_message-id',\n",
    "'label']\n",
    "\n",
    "feature_list = ['domain_val_message-id',\n",
    "       'domain_match_message-id_from', 'domain_match_from_return-path',\n",
    "       'domain_match_message-id_return-path', 'domain_match_message-id_sender',\n",
    "       'domain_match_message-id_reply-to', 'domain_match_return-path_reply-to',\n",
    "       'domain_match_reply-to_to', 'domain_match_to_in-reply-to',\n",
    "       'domain_match_errors-to_message-id', 'domain_match_errors-to_from',\n",
    "       'domain_match_errors-to_sender', 'domain_match_errors-to_reply-to',\n",
    "       'domain_match_sender_from', 'domain_match_references_reply-to',\n",
    "       'domain_match_references_in-reply-to', 'domain_match_references_to',\n",
    "       'domain_match_from_reply-to', 'domain_match_to_from',\n",
    "       'domain_match_to_message-id', 'domain_match_to_received', 'label']\n",
    "\n",
    "df_val = df_val[feature_list]\n",
    "\n",
    "X_val = df_val.drop('label', axis=1)\n",
    "y_val = df_val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 22)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_val_message-id</th>\n",
       "      <th>domain_match_message-id_from</th>\n",
       "      <th>domain_match_from_return-path</th>\n",
       "      <th>domain_match_message-id_return-path</th>\n",
       "      <th>domain_match_message-id_sender</th>\n",
       "      <th>domain_match_message-id_reply-to</th>\n",
       "      <th>domain_match_return-path_reply-to</th>\n",
       "      <th>domain_match_reply-to_to</th>\n",
       "      <th>domain_match_to_in-reply-to</th>\n",
       "      <th>domain_match_errors-to_message-id</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_match_errors-to_reply-to</th>\n",
       "      <th>domain_match_sender_from</th>\n",
       "      <th>domain_match_references_reply-to</th>\n",
       "      <th>domain_match_references_in-reply-to</th>\n",
       "      <th>domain_match_references_to</th>\n",
       "      <th>domain_match_from_reply-to</th>\n",
       "      <th>domain_match_to_from</th>\n",
       "      <th>domain_match_to_message-id</th>\n",
       "      <th>domain_match_to_received</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain_val_message-id  domain_match_message-id_from  \\\n",
       "0                      0                             0   \n",
       "1                      0                             1   \n",
       "2                      0                             1   \n",
       "3                      0                             1   \n",
       "4                      0                             0   \n",
       "\n",
       "   domain_match_from_return-path  domain_match_message-id_return-path  \\\n",
       "0                              0                                    1   \n",
       "1                              0                                    0   \n",
       "2                              0                                    0   \n",
       "3                              1                                    1   \n",
       "4                              0                                    0   \n",
       "\n",
       "   domain_match_message-id_sender  domain_match_message-id_reply-to  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 0   \n",
       "2                               0                                 0   \n",
       "3                               0                                 0   \n",
       "4                               0                                 0   \n",
       "\n",
       "   domain_match_return-path_reply-to  domain_match_reply-to_to  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "\n",
       "   domain_match_to_in-reply-to  domain_match_errors-to_message-id  ...  \\\n",
       "0                            0                                  0  ...   \n",
       "1                            0                                  0  ...   \n",
       "2                            0                                  0  ...   \n",
       "3                            0                                  0  ...   \n",
       "4                            0                                  0  ...   \n",
       "\n",
       "   domain_match_errors-to_reply-to  domain_match_sender_from  \\\n",
       "0                                0                         0   \n",
       "1                                0                         0   \n",
       "2                                0                         0   \n",
       "3                                0                         0   \n",
       "4                                0                         0   \n",
       "\n",
       "   domain_match_references_reply-to  domain_match_references_in-reply-to  \\\n",
       "0                                 0                                    0   \n",
       "1                                 0                                    0   \n",
       "2                                 0                                    1   \n",
       "3                                 0                                    0   \n",
       "4                                 0                                    0   \n",
       "\n",
       "   domain_match_references_to  domain_match_from_reply-to  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   domain_match_to_from  domain_match_to_message-id  domain_match_to_received  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     0                           0                         1   \n",
       "4                     0                           0                         0   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XR4Wc3Fqh_W"
   },
   "source": [
    "# **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__criterion': 'entropy', 'rf__max_features': 'log2', 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 3, 'rf__n_estimators': 100} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(criterion='entropy',\n",
      "                                        max_features='log2', min_samples_leaf=2,\n",
      "                                        min_samples_split=3))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 76.73469387755102\n",
      "F1 Score: 81.12582781456953\n",
      "Recall: 100.0\n",
      "Precision: 68.24512534818942\n",
      "ROC AUC: 76.73469387755102\n",
      "Confusion Matrix: [[131 114]\n",
      " [  0 245]]\n",
      "CPU times: user 392 ms, sys: 57.5 ms, total: 449 ms\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Original: Hyperparameter Tuning with GRID SEARCH\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"rf\", RandomForestClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'rf__n_estimators': [100, 150],\n",
    "                  'rf__criterion': ['entropy', 'gini'],\n",
    "                  'rf__min_samples_split': [2, 3],\n",
    "                  'rf__min_samples_leaf': [1, 2],\n",
    "                  'rf__max_features': ['sqrt', 'log2']} # removed 'auto' \n",
    "         \n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "rf_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "original_predict = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, original_predict)*100)\n",
    "print('F1 Score:', f1_score(y_test, original_predict)*100)\n",
    "print('Recall:', recall_score(y_test, original_predict)*100)\n",
    "print('Precision:', precision_score(y_test, original_predict)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, original_predict)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, original_predict))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novelty: Trying hyperparameter tuning with RANDOM SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are: {'rf__n_estimators': 150, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 2, 'rf__max_features': 'sqrt', 'rf__criterion': 'entropy'}\n",
      "Best score is: 0.979611650485437\n",
      "Best model is: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(criterion='entropy', min_samples_leaf=2,\n",
      "                                        n_estimators=150))])\n",
      "\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 76.73469387755102\n",
      "F1 Score: 81.12582781456953\n",
      "Recall: 100.0\n",
      "Precision: 68.24512534818942\n",
      "ROC AUC: 76.73469387755102\n",
      "Confusion Matrix: [[131 114]\n",
      " [  0 245]]\n",
      "CPU times: user 411 ms, sys: 56.6 ms, total: 467 ms\n",
      "Wall time: 3.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter Tuning with RANDOM SEARCH\n",
    "from scipy.stats import randint\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"rf\", RandomForestClassifier())\n",
    "                ])\n",
    "\n",
    "rs_space={'rf__n_estimators': [100, 150],\n",
    "               'rf__criterion': ['entropy', 'gini'],\n",
    "               'rf__min_samples_split': [2, 3],\n",
    "               'rf__min_samples_leaf': [1, 2],\n",
    "               'rf__max_features': ['sqrt', 'log2']\n",
    "         }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_random = RandomizedSearchCV(pipe, rs_space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=10)\n",
    "model_random = rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_df = pd.DataFrame(model_random.cv_results_)\n",
    "print('Best hyperparameters are: '+str(model_random.best_params_))\n",
    "print('Best score is: '+str(model_random.best_score_))\n",
    "print('Best model is: '+str(model_random.best_estimator_))\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = model_random.best_estimator_\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "original_predict = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('\\nORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, original_predict)*100)\n",
    "print('F1 Score:', f1_score(y_test, original_predict)*100)\n",
    "print('Recall:', recall_score(y_test, original_predict)*100)\n",
    "print('Precision:', precision_score(y_test, original_predict)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, original_predict)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, original_predict))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#rf_df[rf_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBX1OIt-s3J8"
   },
   "source": [
    "# **MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlp__activation': 'relu', 'mlp__alpha': 0.001, 'mlp__hidden_layer_sizes': (40, 40), 'mlp__learning_rate': 'constant', 'mlp__solver': 'sgd'} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(40, 40),\n",
      "                               max_iter=500, solver='sgd'))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.67441860465115\n",
      "F1 Score: 97.86476868327402\n",
      "Recall: 97.86476868327402\n",
      "Precision: 97.86476868327402\n",
      "ROC AUC: 97.65578859695616\n",
      "Confusion Matrix: [[229   6]\n",
      " [  6 275]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 94.08163265306122\n",
      "F1 Score: 94.06952965235175\n",
      "Recall: 93.87755102040816\n",
      "Precision: 94.26229508196722\n",
      "ROC AUC: 94.08163265306123\n",
      "Confusion Matrix: [[231  14]\n",
      " [ 15 230]]\n",
      "CPU times: user 20.1 s, sys: 559 ms, total: 20.6 s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Original: Hyperparameter Tuning with GRID SEARCH\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"mlp\", MLPClassifier(max_iter=500))\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'mlp__hidden_layer_sizes': [(20,), (20,20), (40,), (40,40)],\n",
    "                   'mlp__activation': ['tanh', 'relu'],\n",
    "                   'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "                   'mlp__solver': ['adam', 'sgd'],\n",
    "                   'mlp__alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "mlp_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#mlp_df[mlp_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novelty: Trying hyperparameter tuning with RANDOM SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters are: {'mlp__solver': 'sgd', 'mlp__learning_rate': 'adaptive', 'mlp__hidden_layer_sizes': (40, 40), 'mlp__alpha': 0.0001, 'mlp__activation': 'relu'}\n",
      "Best score is: 0.9800975495209521\n",
      "Best model is: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(hidden_layer_sizes=(40, 40),\n",
      "                               learning_rate='adaptive', max_iter=500,\n",
      "                               solver='sgd'))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 93.46938775510203\n",
      "F1 Score: 93.57429718875503\n",
      "Recall: 95.10204081632652\n",
      "Precision: 92.09486166007905\n",
      "ROC AUC: 93.46938775510203\n",
      "Confusion Matrix: [[225  20]\n",
      " [ 12 233]]\n",
      "CPU times: user 12.2 s, sys: 278 ms, total: 12.5 s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameter Tuning with RANDOM SEARCH\n",
    "from scipy.stats import randint\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"mlp\", MLPClassifier(max_iter=500))\n",
    "                ])\n",
    "\n",
    "rs_space={'mlp__hidden_layer_sizes': [(20,), (20,20), (40,), (40,40)],\n",
    "            'mlp__activation': ['tanh', 'relu'],\n",
    "            'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "            'mlp__solver': ['adam', 'sgd'],\n",
    "            'mlp__alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "mlp_random = RandomizedSearchCV(pipe, rs_space, scoring='accuracy', n_jobs=-1, cv=3)\n",
    "model_random = mlp_random.fit(X_train, y_train)\n",
    "\n",
    "mlp_df = pd.DataFrame(model_random.cv_results_)\n",
    "print('Best hyperparameters are: '+str(model_random.best_params_))\n",
    "print('Best score is: '+str(model_random.best_score_))\n",
    "print('Best model is: '+str(model_random.best_estimator_))\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = model_random.best_estimator_\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#mlp_df[mlp_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'lr__fit_intercept': True, 'lr__penalty': 'l2', 'lr__solver': 'newton-cg', 'lr__tol': 0.0001} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=1, max_iter=2000, solver='newton-cg'))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.67441860465115\n",
      "F1 Score: 97.87234042553192\n",
      "Recall: 98.22064056939502\n",
      "Precision: 97.52650176678446\n",
      "ROC AUC: 97.62095858256986\n",
      "Confusion Matrix: [[228   7]\n",
      " [  5 276]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 80.81632653061224\n",
      "F1 Score: 76.61691542288557\n",
      "Recall: 62.857142857142854\n",
      "Precision: 98.08917197452229\n",
      "ROC AUC: 80.81632653061224\n",
      "Confusion Matrix: [[242   3]\n",
      " [ 91 154]]\n",
      "CPU times: user 1.21 s, sys: 661 ms, total: 1.87 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Original: Hyperparameter Tuning with GRID SEARCH\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"lr\", LogisticRegression(max_iter=2000))\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'lr__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'lr__fit_intercept': [True, False],\n",
    "                  'lr__tol': [0.0001, 0.001],\n",
    "                  'lr__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                  'lr__C': [0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "lr_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#lr_df[lr_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1, 'svc__degree': 3, 'svc__kernel': 'rbf', 'svc__tol': 0.001} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()), ('svc', SVC(C=1))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.48062015503875\n",
      "F1 Score: 97.71528998242532\n",
      "Recall: 98.93238434163702\n",
      "Precision: 96.52777777777779\n",
      "ROC AUC: 97.33853259635043\n",
      "Confusion Matrix: [[225  10]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 81.22448979591836\n",
      "F1 Score: 83.51254480286738\n",
      "Recall: 95.10204081632652\n",
      "Precision: 74.4408945686901\n",
      "ROC AUC: 81.22448979591836\n",
      "Confusion Matrix: [[165  80]\n",
      " [ 12 233]]\n",
      "CPU times: user 1.5 s, sys: 272 ms, total: 1.77 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"svc\", SVC())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'svc__C': [0.1, 1, 10],\n",
    "                  'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                  'svc__degree': [3, 4, 5],\n",
    "                  'svc__tol': [0.001, 0.0001, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "svm_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#svm_df[svm_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__ccp_alpha': 0, 'dt__criterion': 'entropy', 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('dt',\n",
      "                 DecisionTreeClassifier(ccp_alpha=0, criterion='entropy'))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 76.73469387755102\n",
      "F1 Score: 81.12582781456953\n",
      "Recall: 100.0\n",
      "Precision: 68.24512534818942\n",
      "ROC AUC: 76.73469387755102\n",
      "Confusion Matrix: [[131 114]\n",
      " [  0 245]]\n",
      "CPU times: user 337 ms, sys: 52.7 ms, total: 390 ms\n",
      "Wall time: 581 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"dt\", DecisionTreeClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'dt__criterion': ['entropy', 'gini'],\n",
    "                  'dt__min_samples_split': [2, 3, 4],\n",
    "                  'dt__min_samples_leaf': [1, 2, 3],\n",
    "                  'dt__ccp_alpha': [0, 0.005, 0.01, 0.025, 0.05, 0.1]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "dt_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#dt_df[dt_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naive Bayes (Gaussian)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gnb__var_smoothing': 1e-08} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('gnb', GaussianNB(var_smoothing=1e-08))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 87.59689922480621\n",
      "F1 Score: 89.64401294498381\n",
      "Recall: 98.57651245551602\n",
      "Precision: 82.19584569732937\n",
      "ROC AUC: 86.5222987809495\n",
      "Confusion Matrix: [[175  60]\n",
      " [  4 277]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 50.0\n",
      "F1 Score: 0.0\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "ROC AUC: 50.0\n",
      "Confusion Matrix: [[245   0]\n",
      " [245   0]]\n",
      "CPU times: user 30 ms, sys: 6.08 ms, total: 36.1 ms\n",
      "Wall time: 50.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"gnb\", GaussianNB())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'gnb__var_smoothing': [1E-9, 1E-10, 1E-8]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "nb_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#nb_df[nb_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab__algorithm': 'SAMME.R', 'ab__learning_rate': 0.95, 'ab__n_estimators': 50} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('ab', AdaBoostClassifier(learning_rate=0.95))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.28682170542635\n",
      "F1 Score: 97.52650176678446\n",
      "Recall: 98.22064056939502\n",
      "Precision: 96.84210526315789\n",
      "ROC AUC: 97.19542666767624\n",
      "Confusion Matrix: [[226   9]\n",
      " [  5 276]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 81.22448979591836\n",
      "F1 Score: 84.19243986254295\n",
      "Recall: 100.0\n",
      "Precision: 72.70029673590504\n",
      "ROC AUC: 81.22448979591836\n",
      "Confusion Matrix: [[153  92]\n",
      " [  0 245]]\n",
      "CPU times: user 601 ms, sys: 106 ms, total: 707 ms\n",
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"ab\", AdaBoostClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'ab__n_estimators': [50, 100, 150, 200],\n",
    "                  'ab__learning_rate': [0.95, 1, 1.05, 1.25, 1.5, 1.75, 2],\n",
    "                  'ab__algorithm': ['SAMME', 'SAMME.R']}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "ab_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#ab_df[ab_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GradientBoostClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gbc__learning_rate': 0.25, 'gbc__max_features': 'sqrt', 'gbc__n_estimators': 100} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('gbc',\n",
      "                 GradientBoostingClassifier(learning_rate=0.25,\n",
      "                                            max_features='sqrt'))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 76.73469387755102\n",
      "F1 Score: 81.12582781456953\n",
      "Recall: 100.0\n",
      "Precision: 68.24512534818942\n",
      "ROC AUC: 76.73469387755102\n",
      "Confusion Matrix: [[131 114]\n",
      " [  0 245]]\n",
      "CPU times: user 502 ms, sys: 80.2 ms, total: 583 ms\n",
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"gbc\", GradientBoostingClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'gbc__max_features': ['sqrt', 'log2'], # Removed 'auto'\n",
    "                   'gbc__learning_rate': [0.05, 0.1, 0.2, 0.25, 0.30, 0.35, 0.40, 0.5, 0.6, 0.7, 0.9],\n",
    "                   'gbc__n_estimators': [100, 200]\n",
    "                  }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "gb_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#gb_df[gb_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__algorithm': 'auto', 'knn__leaf_size': 15, 'knn__n_neighbors': 20, 'knn__p': 1, 'knn__weights': 'distance'} \n",
      "\n",
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(leaf_size=15, n_neighbors=20, p=1,\n",
      "                                      weights='distance'))])\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 72.24489795918367\n",
      "F1 Score: 77.40863787375415\n",
      "Recall: 95.10204081632652\n",
      "Precision: 65.26610644257703\n",
      "ROC AUC: 72.24489795918367\n",
      "Confusion Matrix: [[121 124]\n",
      " [ 12 233]]\n",
      "CPU times: user 299 ms, sys: 86.7 ms, total: 386 ms\n",
      "Wall time: 401 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"knn\", KNeighborsClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid_list = {'knn__n_neighbors': [1, 10, 20],\n",
    "                  'knn__weights': ['uniform', 'distance'],\n",
    "                  'knn__p': [1, 2],\n",
    "                  'knn__algorithm': ['auto'],\n",
    "                  'knn__leaf_size': [15, 30, 45]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid_list, cv=10, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Find the best hyperparameters (using 10 fold CV with the hold out fold being the validation set)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Check the hyperparameter results\n",
    "knn_df = pd.DataFrame(grid.cv_results_)\n",
    "print(grid.best_params_, '\\n')\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the best performing model on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "### Validation\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Get the evaluation metrics\n",
    "print('ORIGINAL EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "print('Recall:', recall_score(y_test, predictions)*100)\n",
    "print('Precision:', precision_score(y_test, predictions)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Get the validation evaluation metrics\n",
    "print('\\nVALIDATION EVALUATION METRICS')\n",
    "print('-----------------------------')\n",
    "print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "#knn_df[knn_df['rank_test_score'] <= 5].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 80.40816326530611\n",
      "F1 Score: 82.91814946619216\n",
      "Recall: 95.10204081632652\n",
      "Precision: 73.50157728706624\n",
      "ROC AUC: 80.40816326530611\n",
      "Confusion Matrix: [[161  84]\n",
      " [ 12 233]]\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 93.06122448979592\n",
      "F1 Score: 93.19999999999999\n",
      "Recall: 95.10204081632652\n",
      "Precision: 91.37254901960785\n",
      "ROC AUC: 93.06122448979592\n",
      "Confusion Matrix: [[223  22]\n",
      " [ 12 233]]\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 72.6530612244898\n",
      "F1 Score: 77.66666666666667\n",
      "Recall: 95.10204081632652\n",
      "Precision: 65.63380281690141\n",
      "ROC AUC: 72.65306122448979\n",
      "Confusion Matrix: [[123 122]\n",
      " [ 12 233]]\n",
      "ORIGINAL EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 97.86821705426357\n",
      "F1 Score: 98.05996472663139\n",
      "Recall: 98.93238434163702\n",
      "Precision: 97.2027972027972\n",
      "ROC AUC: 97.76406451124403\n",
      "Confusion Matrix: [[227   8]\n",
      " [  3 278]]\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "VALIDATION EVALUATION METRICS\n",
      "-----------------------------\n",
      "Accuracy: 92.85714285714286\n",
      "F1 Score: 93.01397205588823\n",
      "Recall: 95.10204081632652\n",
      "Precision: 91.015625\n",
      "ROC AUC: 92.85714285714285\n",
      "Confusion Matrix: [[222  23]\n",
      " [ 12 233]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "'''\n",
    "base_learners = [('rf', RandomForestClassifier(criterion='entropy', max_features='auto', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "'''\n",
    "\n",
    "base_learners_set1 = [('rf', RandomForestClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance'))]\n",
    "\n",
    "base_learners_set2 = [('rf', RandomForestClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners_set3 = [('rf', RandomForestClassifier(criterion='entropy',  min_samples_leaf=1, min_samples_split=3, n_estimators=100)),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners_set4 = [('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners = []\n",
    "base_learners.append(base_learners_set1)\n",
    "base_learners.append(base_learners_set2)\n",
    "base_learners.append(base_learners_set3)\n",
    "base_learners.append(base_learners_set4)\n",
    "\n",
    "for base_learner_group in base_learners:\n",
    "\n",
    "    meta_learner = LogisticRegression()\n",
    "\n",
    "    clf = StackingClassifier(estimators=base_learner_group, final_estimator=meta_learner)\n",
    "\n",
    "    # Train the stacked model on the full training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    ### Validation\n",
    "    val_pred = clf.predict(X_val)\n",
    "\n",
    "    # Get the evaluation metrics\n",
    "    print('ORIGINAL EVALUATION METRICS')\n",
    "    print('-----------------------------')\n",
    "    print('Accuracy:', accuracy_score(y_test, predictions)*100)\n",
    "    print('F1 Score:', f1_score(y_test, predictions)*100)\n",
    "    print('Recall:', recall_score(y_test, predictions)*100)\n",
    "    print('Precision:', precision_score(y_test, predictions)*100)\n",
    "    print('ROC AUC:', roc_auc_score(y_test, predictions)*100)\n",
    "    print('Confusion Matrix:', confusion_matrix(y_test, predictions))\n",
    "    print('-----------------------------------------\\n')\n",
    "\n",
    "    # Get the validation evaluation metrics\n",
    "    print('\\nVALIDATION EVALUATION METRICS')\n",
    "    print('-----------------------------')\n",
    "    print('Accuracy:', accuracy_score(y_val, val_pred)*100)\n",
    "    print('F1 Score:', f1_score(y_val, val_pred)*100)\n",
    "    print('Recall:', recall_score(y_val, val_pred)*100)\n",
    "    print('Precision:', precision_score(y_val, val_pred)*100)\n",
    "    print('ROC AUC:', roc_auc_score(y_val, val_pred)*100)\n",
    "    print('Confusion Matrix:', confusion_matrix(y_val, val_pred))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sCMEqns8jY-1",
    "F5A997Ekjh0E",
    "KvWjb8GwOM-y",
    "rJJ4WHSBFTWc",
    "nqHSyA4SyJ7K",
    "xhkNe2ql-cFP",
    "fMwsPWxpi2cG",
    "-_nEjwFOjUDI",
    "MyekmTK3q5TC",
    "RkQzXPCXUxme",
    "P1zXPP6trxSN",
    "iGZ561te2ONO",
    "rffvHbuzGO8c"
   ],
   "name": "Capstone Project - Email Headers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
